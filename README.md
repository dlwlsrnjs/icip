# EEG Connectivity Multi-View Learning for ADHD Classification

EEG connectivity ì´ë¯¸ì§€ë¥¼ ì´ìš©í•œ ADHD vs Control ë¶„ë¥˜ë¥¼ ìœ„í•œ Multi-View Learning í”„ë¡œì íŠ¸

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

- **ëª©í‘œ**: EEG connectivity ì´ë¯¸ì§€ë¥¼ í™œìš©í•˜ì—¬ ADHD í™˜ìì™€ ì •ìƒ ëŒ€ì¡°êµ°ì„ ë¶„ë¥˜
- **ë°ì´í„°**: 121ëª… (ADHD: 61ëª…, Control: 60ëª…)
- **Multi-View**: 3ê°€ì§€ connectivity ë°©ë²• (FCM, PCC, PLV) Ã— 5ê°œ ì£¼íŒŒìˆ˜ ë°´ë“œ = 15 views
- **ëª¨ë¸**: MVSelect + Paper-Inspired Att-CNN (Neuroinformatics 2024)

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
icip/
â”œâ”€â”€ EEG_MVSelect/              # Main project
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ paper_exact_attention.py    # Lightweight Att-CNN (360K params)
â”‚   â”‚   â”‚   â”œâ”€â”€ resnet.py                   # ResNet variants
â”‚   â”‚   â”‚   â”œâ”€â”€ mvselect.py                 # Multi-view selection (DQN)
â”‚   â”‚   â”‚   â””â”€â”€ multiview_base.py
â”‚   â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”‚   â””â”€â”€ eeg_connectivity.py         # EEG dataset loader with CV
â”‚   â”‚   â””â”€â”€ trainer.py                      # Training & evaluation
â”‚   â”œâ”€â”€ main.py                             # Entry point
â”‚   â”œâ”€â”€ train_improved.sh                   # Optimized training script
â”‚   â”œâ”€â”€ train_5fold_cv.sh                   # 5-Fold Cross-Validation
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ FCM_Images_HERMES_v2/      # Dataset (not included)
â””â”€â”€ subject_labels.csv         # Subject labels
```

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

### 1. **Paper-Inspired Att-CNN**
Neuroinformatics 2024 ë…¼ë¬¸ ê¸°ë°˜ ê²½ëŸ‰ ëª¨ë¸:
- 3 Conv layers (32â†’64â†’128 filters)
- Channel Attention (reduction=8)
- 360K parameters (vs ResNet50 25M)
- BatchNorm + Dropout regularization

### 2. **Multi-View Learning**
- 15ê°œ viewë¥¼ í†µí•©í•˜ì—¬ robustí•œ ë¶„ë¥˜
- Max aggregation across views
- Optional: MVSelectë¡œ ì¤‘ìš”í•œ viewë§Œ ì„ íƒ (3/15)

### 3. **5-Fold Cross-Validation**
- ì‹ ë¢°ì„± ìˆëŠ” ì„±ëŠ¥ í‰ê°€
- ê° foldë§ˆë‹¤ stratified split (class balance ìœ ì§€)
- Train: ~97, Val: 8, Test: ~24 samples per fold

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ì„¤ì¹˜
```bash
cd EEG_MVSelect
pip install -r requirements.txt
```

### ë°ì´í„°ì…‹ ì¤€ë¹„
```
FCM_Images_HERMES_v2/
â”œâ”€â”€ FCM/
â”‚   â””â”€â”€ v{subject_id}_{band}.png
â”œâ”€â”€ PCC/
â”‚   â””â”€â”€ v{subject_id}_{band}.png
â””â”€â”€ PLV/
    â””â”€â”€ v{subject_id}_{band}.png
```

### í•™ìŠµ
```bash
# ê°œì„ ëœ ì„¤ì •ìœ¼ë¡œ 5-Fold CV
./train_improved.sh

# ë‹¨ì¼ í•™ìŠµ
python main.py \
    --use_paper_exact \
    --data_root ../FCM_Images_HERMES_v2 \
    --batch_size 16 \
    --epochs 80 \
    --lr 5e-4 \
    --weight_decay 1e-4
```

## ğŸ“Š ì„±ëŠ¥ ê²°ê³¼

### ê°œì„  ì „ (ê³¼ë„í•œ augmentation + ë†’ì€ regularization)
- 5-Fold CV Average: **61.67% Â± 7.17%**
- Train Acc: 60-70% (underfitting)
- Val Acc: 50-62.5% (random ìˆ˜ì¤€)

### ê°œì„  í›„ (ìµœì†Œ augmentation + ë‚®ì€ regularization)
- í˜„ì¬ ì§„í–‰ ì¤‘
- Fold 2 Test: **75.00%**
- Fold 3 Val: **87.50%**
- Train Acc: 80-88% (ì ì ˆí•œ í•™ìŠµ)

### ì£¼ìš” ê°œì„ ì‚¬í•­
1. **Data Augmentation ìµœì†Œí™”**: Flip/Rotation ì œê±° â†’ ColorJitterë§Œ ì‚¬ìš©
2. **Regularization ì™„í™”**: Dropout 0.5â†’0.3, Weight Decay 5e-4â†’1e-4
3. **Learning Rate ê°ì†Œ**: 1e-3 â†’ 5e-4

## ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„°

```python
# Model
architecture = "Paper-Inspired Att-CNN"
num_params = 360322
input_size = (224, 224)
num_views = 15

# Training
batch_size = 16
epochs = 80
lr = 5e-4
weight_decay = 1e-4
optimizer = "SGD with momentum 0.9"
scheduler = "Cosine Annealing"

# Augmentation (Train only)
ColorJitter(brightness=0.1, contrast=0.1)
Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
```

## ğŸ“ˆ ëª¨ë¸ ì•„í‚¤í…ì²˜

```
Input: [B, 15, 3, 224, 224]
  â†“
Conv1(32) + BN + ReLU + MaxPool(2)  â†’ [B, 15, 32, 112, 112]
  â†“
Conv2(64) + BN + ReLU               â†’ [B, 15, 64, 112, 112]
  â†“
Conv3(128) + BN + ReLU              â†’ [B, 15, 128, 112, 112]
  â†“
Channel Attention (reduction=8)     â†’ [B, 15, 128, 112, 112]
  â†“
MaxPool(2) + AdaptiveAvgPool(4Ã—4)   â†’ [B, 15, 128, 4, 4]
  â†“
Max Aggregation across views        â†’ [B, 128, 4, 4]
  â†“
Flatten                             â†’ [B, 2048]
  â†“
Dense(128) + ReLU + Dropout(0.2)    â†’ [B, 128]
  â†“
Dense(2)                            â†’ [B, 2]
```

## ğŸ“ ì°¸ê³  ë¬¸í—Œ

- Neuroinformatics 2024: EEG Connectivity with Channel Attention for ADHD Classification
- MVSelect: DQN-based Multi-View Selection

## ğŸ‘¤ ì‘ì„±ì

dlwlsrnjs

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License
